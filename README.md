[![Build Status](https://travis-ci.org/japaric/criterion.rs.svg?branch=master)](https://travis-ci.org/japaric/criterion.rs)

# criterion.rs

This is a port (with a few modifications) of
[Haskell "criterion" benchmarking library](http://www.serpentine.com/blog/2009/09/29/criterion-a-new-benchmarking-library-for-haskell)
to Rust.

Addresses [mozilla/rust#6812](https://github.com/mozilla/rust/issues/6812) and
I hope it'll help with
[mozilla/rust#7532](https://github.com/mozilla/rust/issues/7532)

I encourage you to look at this
[braindump](http://japaric.github.io/criterion-braindump), for an explanation
(with plots!) of how criterion works.

## Run the examples

```
$ make && make test
estimating the cost of precise_time_ns()
> warming up for 500 ms
> collecting 100 measurements, 671088 iters each in estimated 1.1822 s
> found 5 outliers among 100 measurements (5.00%)
  > 1 (1.00%) high mild
  > 4 (4.00%) high severe
> estimating statistics
  > bootstrapping sample with 100000 resamples
  > mean:   17.620 ns ± 5.7328 ps [17.609 ns 17.632 ns] 95% CI
  > SD:     56.656 ps ± 6.6899 ps [44.233 ps 69.918 ps] 95% CI
  > median: 17.631 ns ± 10.929 ps [17.593 ns 17.632 ns] 95% CI
  > MAD:    56.522 ps ± 5.4038 ps [44.654 ps 68.040 ps] 95% CI

(...)
benchmarking fib_15
> warming up for 500 ms
> collecting 100 measurements, 2621 iters each in estimated 1.2882 s
> found 6 outliers among 100 measurements (6.00%)
  > 4 (4.00%) high mild
  > 2 (2.00%) high severe
> estimating statistics
  > bootstrapping sample with 100000 resamples
  > mean:   4.9175 us ± 1.5812 ns [4.9146 us 4.9208 us] 95% CI
  > SD:     15.618 ns ± 1.5828 ns [12.433 ns 18.633 ns] 95% CI
  > median: 4.9184 us ± 1.2377 ns [4.9138 us 4.9192 us] 95% CI
  > MAD:    14.200 ns ± 1.5540 ns [11.688 ns 18.286 ns] 95% CI
> testing hypotheses against previous sample
  > H0: both samples belong to the same population
    > bootstrapping with 100000 resamples
    > both mean and median contradict H0 (0.00026, 0.00151 < 0.05)
  > H0: new mean <= old mean
  > Ha: mean regressed by 0.18%
    > bootstrapping with 100000 resamples
    > no evidence to contradict H0 (0.22496 > 0.05)
  > H0: new median <= old median
  > Ha: median regressed by 0.21%
    > bootstrapping with 100000 resamples
    > strong evidence to contradict H0 (0.04635 < 0.05)
(...)
```

## Done so far

* Estimation of the cost of reading the clock (`precise_time_ns()`)
* Outlier classification using the box plot method (IQR criteria)
* Removal of severe outliers (this is **not** done in the original criterion)
* Bootstrapping: point estimate, standard error and confidence interval
* Convert to library
* Bencher-like interface
* Bencher configuration
* Benchmark groups
* Some examples
* Save metrics to json file
* Hypothesis testing
  * Do the old and new sample belong to the same population?
  * Has the benchmark regressed by at least 3 standard errors?

## Not (yet?) ported from the original

* outlierVariance, this method computes the influence of the outliers on the
  variance of the sample
  * this still looks too magical to me, using only the sample size, and the
    point estimates of the mean and the standard deviation, the author
    classifies the effect of the outliers on the sample variance
    * there are no references of the method used to do this
  * some rough ideas that might accomplish this:
    * the SEM (standard error of the mean) is the variance of the population
      over the square root of the sample size, I could compute the variance of
      the population and compare it against the bootstrapped variance.
    * Fit the bootstrapped distribution to a normal distribution, and look at
      the R squared.
    * Look at the skewness of the bootstrap distributions.

## TODO

* More testing
* Redirect benchmark stdout to /dev/null
* Compare the results generated by criterion.rs with the results generated by
  Rust Bencher algorithm
  * Rust Bencher reports smaller times in some benchmarks
* Compare the current basic bootstrap against the BCa (bias corrected and
  accelerated) bootstrap
* Check if the sample is garbage
  * may be caused by CPU throttling or CPU usage peaks
    * should translate into high variance in the sample
  * background constant CPU usage should be hard to detect
    * this affects more the mean than the variance
* Documentation

# Wishlist

* Plot the [PDF](http://en.wikipedia.org/wiki/Probability_density_function) of
  the sample
  * computing the PDF is expensive
  * PDF from the sample is not too reliable, a PDF from the bootstrap would be
    better, but that would be even more expensive
  * need plotting library
    * gnuplot? is the license compatible with Apache/MIT?
  * How to select the X range of the PDF
* Interface to benchmark external programs (written in other languages)
  * Addresses the last point in
    [mozilla/rust#7532](https://github.com/mozilla/rust/issues/7532)
  * Something like [eulermark.rs](https://github.com/japaric/eulermark.rs)
    * See eulermark results [here](http://japaric.github.io/eulermark.rs)

## Unresolved questions

* Is sensible to remove the severe outliers in **all** the cases?
  * Removing outliers will always reduce the variance in the sample
* Can we continuously remove the severe outliers from the sample, until the box
  plot analysis yields no more severe outliers?
* When performing several benchmarks, heavy benchmark may affect the benchmarks
  that follow (hot CPU?), how do we address this?
  * Add a cooldown time between benchmarks?

## License

criterion.rs is dual licensed under the Apache 2.0 license and the MIT license.

See LICENSE-APACHE and LICENSE-MIT for more details.
